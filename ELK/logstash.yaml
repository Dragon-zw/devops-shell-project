# 创建 logstash.yaml 并部署服务
apiVersion: v1
kind: Service # Service 资源类型
metadata:
  name: logstash
  namespace: kube-logging
spec:
  ports:
  - port: 5044 # 接收 filebeats 的数据
    targetPort: beats
  selector:
    type: logstash
  clusterIP: None
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: logstash
  namespace: kube-logging
spec:
  selector:
    matchLabels:
      type: logstash
  template:
    metadata:
      labels:
        type: logstash
        srv: srv-logstash
    spec:
      containers:
      - image: docker.io/kubeimages/logstash:7.9.3 # 该镜像支持arm64和amd64两种架构 
        name: logstash
        ports:
        - containerPort: 5044
          name: beats
        command:
        - logstash
        - '-f'
        - '/etc/logstash_c/logstash.conf'
        env:
        - name: "XPACK_MONITORING_ELASTICSEARCH_HOSTS"
          value: "http://elasticsearch-logging:9200"
        volumeMounts:
        - name: config-volume
          mountPath: /etc/logstash_c/
        - name: config-yml-volume
          mountPath: /usr/share/logstash/config/
        - name: timezone
          mountPath: /etc/localtime
        resources: #logstash一定要加上资源限制，避免对其他业务造成资源抢占影响 
          limits:
            cpu: 1000m
            memory: 2048Mi
          requests:
            cpu: 512m
            memory: 512Mi
      volumes:
      - name: config-volume
        configMap:
          name: logstash-conf
          items:
          - key: logstash.conf
            path: logstash.conf
      - name: timezone
        hostPath:
          path: /etc/localtime
      - name: config-yml-volume
        configMap:
          name: logstash-yml
          items:
          - key: logstash.yml
            path: logstash.yml

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: logstash-conf
  namespace: kube-logging
  labels:
    type: logstash
data:
  logstash.conf: "input {\n  # beats 输入数据\n  beats { \n    # beats 的输入数据的端口\n    port => 5044 \n  } \n} \nfilter {\n  # 处理 ingress 日志 \n  if [kubernetes][container][name] == \"nginx-ingress-controller\" {\n    json {\n      source => \"message\" \n      target => \"ingress_log\" \n    }\n    if [ingress_log][requesttime] { \n      mutate { \n        convert => [\"[ingress_log][requesttime]\", \"float\"] \n      }\n    }\n    if [ingress_log][upstremtime] { \n      mutate { \n        convert => [\"[ingress_log][upstremtime]\", \"float\"] \n      }\n    } \n    if [ingress_log][status] { \n      mutate { \n        convert => [\"[ingress_log][status]\", \"float\"] \n      }\n    }\n    if  [ingress_log][httphost] and [ingress_log][uri] {\n      mutate { \n        add_field => {\"[ingress_log][entry]\" => \"%{[ingress_log][httphost]}%{[ingress_log][uri]}\"} \n      } \n      mutate { \n        split => [\"[ingress_log][entry]\",\"/\"] \n      } \n      if [ingress_log][entry][1] { \n        mutate { \n          add_field => {\"[ingress_log][entrypoint]\" => \"%{[ingress_log][entry][0]}/%{[ingress_log][entry][1]}\"} \n          remove_field => \"[ingress_log][entry]\" \n        }\n      } else { \n        mutate { \n          add_field => {\"[ingress_log][entrypoint]\" => \"%{[ingress_log][entry][0]}/\"} \n          remove_field => \"[ingress_log][entry]\" \n        }\n      }\n    }\n  }\n  # 处理以srv进行开头的业务服务日志 \n  if [kubernetes][container][name] =~ /^srv*/ { \n    json { \n      source => \"message\" \n      target => \"tmp\" \n    } \n    if [kubernetes][namespace] == \"kube-logging\" { \n      drop{} \n    } \n    if [tmp][level] { \n      mutate{ \n        add_field => {\"[applog][level]\" => \"%{[tmp][level]}\"} \n      } \n      if [applog][level] == \"debug\"{ \n        drop{} \n      } \n    } \n    if [tmp][msg] { \n      mutate { \n        add_field => {\"[applog][msg]\" => \"%{[tmp][msg]}\"} \n      } \n    } \n    if [tmp][func] { \n      mutate { \n        add_field => {\"[applog][func]\" => \"%{[tmp][func]}\"} \n      } \n    } \n    if [tmp][cost]{ \n      if \"ms\" in [tmp][cost] { \n        mutate { \n          split => [\"[tmp][cost]\",\"m\"] \n          add_field => {\"[applog][cost]\" => \"%{[tmp][cost][0]}\"} \n          convert => [\"[applog][cost]\", \"float\"] \n        } \n      } else { \n        mutate { \n          add_field => {\"[applog][cost]\" => \"%{[tmp][cost]}\"} \n        }\n      }\n    }\n    if [tmp][method] { \n      mutate { \n        add_field => {\"[applog][method]\" => \"%{[tmp][method]}\"} \n      }\n    }\n    if [tmp][request_url] { \n      mutate { \n        add_field => {\"[applog][request_url]\" => \"%{[tmp][request_url]}\"} \n      } \n    }\n    if [tmp][meta._id] { \n      mutate { \n        add_field => {\"[applog][traceId]\" => \"%{[tmp][meta._id]}\"} \n      } \n    } \n    if [tmp][project] { \n      mutate { \n        add_field => {\"[applog][project]\" => \"%{[tmp][project]}\"} \n      }\n    }\n    if [tmp][time] { \n      mutate { \n        add_field => {\"[applog][time]\" => \"%{[tmp][time]}\"} \n      }\n    }\n    if [tmp][status] { \n      mutate { \n        add_field => {\"[applog][status]\" => \"%{[tmp][status]}\"} \n        convert => [\"[applog][status]\", \"float\"] \n      }\n    }\n  }\n  mutate { \n    rename => [\"kubernetes\", \"k8s\"] \n    remove_field => \"beat\" \n    remove_field => \"tmp\" \n    remove_field => \"[k8s][labels][app]\" \n  }\n}\noutput { \n  elasticsearch { \n    hosts => [\"http://elasticsearch-logging:9200\"] \n    codec => json \n    index => \"logstash-%{+YYYY.MM.dd}\" # 索引名称以logstash+日志进行每日新建，按天进行索引\n  } \n} "
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: logstash-yml
  namespace: kube-logging
  labels:
    type: logstash
data:
  logstash.yml: "http.host: \"0.0.0.0\" \nxpack.monitoring.elasticsearch.hosts: http://elasticsearch-logging:9200"
